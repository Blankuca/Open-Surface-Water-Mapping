{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Script.Image as Image\n",
    "import Script.Validation as Validation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the images that are going to be used are imported and we build the datasets that will be used for training and validation. Those used for training don't need to upload the full image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data from 07/01/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath1 = \"../Sentinel-2/2020_01_07/L2A_07012020_60.tif\"\n",
    "water_path = \"../Sentinel-2/2020_01_07/Shapefiles/Water_Polygon.shp\"\n",
    "ground_path = \"../Sentinel-2/2020_01_07/Shapefiles/Earth_Polygon.shp\"\n",
    "val_07012020 = Validation.make_dataset(water_path,ground_path,filepath1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data from 27/01/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath2 = \"../Sentinel-2/2020_01_27/L2A_27012020_60.tif\"\n",
    "water_path = \"../Sentinel-2/2020_01_27/Shapefiles/Water_Polygon.shp\"\n",
    "ground_path = \"../Sentinel-2/2020_01_27/Shapefiles/Earth_Polygon.shp\"\n",
    "val_27012020 = Validation.make_dataset(water_path,ground_path,filepath2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data from 02/01/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath3 = \"../Sentinel-2/2020_01_02/L2A_02012020_60.tif\"\n",
    "water_path = \"../Sentinel-2/2020_01_02/Shapefiles/Water_Polygon.shp\"\n",
    "ground_path = \"../Sentinel-2/2020_01_02/Shapefiles/Earth_Polygon.shp\"\n",
    "val_02012020 = Validation.make_dataset(water_path,ground_path,filepath3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data from 28/12/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath4 = \"../Sentinel-2/2018_12_28/L2A_28122018_60.tif\"\n",
    "water_path = \"../Sentinel-2/2018_12_28/Shapefiles/Water_Polygon.shp\"\n",
    "ground_path = \"../Sentinel-2/2018_12_28/Shapefiles/Earth_Polygon.shp\"\n",
    "val_28122018 = Validation.make_dataset(water_path,ground_path,filepath4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate training and validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the training set will be separated from the validation. Ideally, the validation dataset shouldn't have clouds. This is either by default, or they need to be cropped out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.concat([val_02012020['df'],val_27012020['df'],val_28122018['df']])\n",
    "training.to_csv(r'CSV/Training.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_07012020 = Image.make_dataset(filepath1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_28122018= Image.make_dataset(filepath4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Blanca",
   "language": "python",
   "name": "blanca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
